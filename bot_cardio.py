# -*- coding: utf-8 -*-
"""Bot_Cardio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QRPxFp7WadrVREFXHbzHik403ovnfyIm
"""

# instale as libs necessárias
!pip install -q torch torchvision torchaudio
!pip install -q scikit-learn pandas joblib matplotlib seaborn
!pip install -q fastapi uvicorn nest_asyncio pyngrok requests

from google.colab import drive
drive.mount('/content/drive')
# então use /content/drive/MyDrive/seu_arquivo.csv

# train_model_colab.py (célula única)
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score
import joblib
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader

# ------------- parâmetros -------------
DATA_PATH = "/content/drive/MyDrive/Cardiovascular Disease dataset.zip"  # ajuste se montou Drive ou nome diferente
FEATURES = ['age','gender','ap_hi','ap_lo','cholesterol','gluc','smoke','alco','active','bmi']
# ---------------------------------------

# 1) carregar
df = pd.read_csv(DATA_PATH, sep=';')  # no dataset Kaggle o separador é ';' — ajuste se necessário
print("linhas:", len(df))
# limpeza básica
# converter idade (dias) para anos
df['age'] = (df['age'] / 365).round(2)
# criar BMI
df['bmi'] = df['weight'] / ((df['height']/100)**2)

# mapear gender para 0/1 (Kaggle: 1=female, 2=male) -> 0/1
if df['gender'].max() > 1:
    df['gender'] = df['gender'] - 1

    # Filtrar valores absurdos (opcional, recomendado)
    df = df[(df['ap_hi'] > 50) & (df['ap_hi'] < 300)]
    df = df[(df['ap_lo'] > 30) & (df['ap_lo'] < 200)]
    df = df[(df['height'] > 100) & (df['height'] < 230)]
    df = df[(df['weight'] > 20) & (df['weight'] < 300)]
    df = df.dropna().reset_index(drop=True)

    # 2) features e label
    X = df[FEATURES].copy()
    y = df['cardio'].values  # 0/1

    # 3) scaler
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # 4) train/test split
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

    # 5) transformar para tensores
    X_train_t = torch.tensor(X_train, dtype=torch.float32)
    y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)
    X_test_t  = torch.tensor(X_test, dtype=torch.float32)
    y_test_t  = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)

    train_ds = TensorDataset(X_train_t, y_train_t)
    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)

    # 6) definir a rede
    class HeartNN(nn.Module):
        def __init__(self, in_dim):
            super().__init__()
            self.net = nn.Sequential(
                nn.Linear(in_dim, 64),
                nn.ReLU(),
                nn.Dropout(0.25),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            )
        def forward(self, x):
            return self.net(x)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = HeartNN(len(FEATURES)).to(device)
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    # 7) treino básico
    epochs = 12
    for epoch in range(1, epochs+1):
        model.train()
        total_loss = 0.0
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            preds = model(xb)
            loss = criterion(preds, yb)
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * xb.size(0)
        # avalia no teste
        model.eval()
        with torch.no_grad():
            preds_test = model(X_test_t.to(device)).cpu().numpy().ravel()
            auc = roc_auc_score(y_test, preds_test)
            preds_bin = (preds_test >= 0.5).astype(int)
            acc = accuracy_score(y_test, preds_bin)
        print(f"Epoch {epoch}/{epochs} loss={(total_loss/len(train_ds)):.4f} AUC={auc:.4f} ACC={acc:.4f}")

    # 8) salvar modelo e scaler
    torch.save(model.state_dict(), "heart_model.pt")
    joblib.dump(scaler, "scaler.pkl")
    print("Modelo salvo: heart_model.pt ; Scaler salvo: scaler.pkl")

import numpy as np, joblib, torch
from math import pow

# carregar
scaler = joblib.load("scaler.pkl")
model = HeartNN(len(FEATURES))
model.load_state_dict(torch.load("heart_model.pt", map_location=torch.device('cpu')))
model.eval()

def predict_dict(d):
    # d: dict com chaves: age (anos), gender (0/1), ap_hi, ap_lo, cholesterol, gluc, smoke, alco, active, height, weight
    # calculamos bmi aqui se o usuário deu peso/altura
    if 'bmi' not in d and ('height' in d and 'weight' in d):
        d['bmi'] = d['weight'] / ((d['height']/100)**2)
    X = np.array([[ d[k] for k in FEATURES ]], dtype=float)
    Xs = scaler.transform(X)
    xt = torch.tensor(Xs, dtype=torch.float32)
    with torch.no_grad():
        prob = model(xt).item()
    return prob

# exemplo
ex = {'age':45, 'gender':1, 'ap_hi':130, 'ap_lo':85, 'cholesterol':2, 'gluc':1, 'smoke':0, 'alco':0, 'active':1, 'height':170, 'weight':75}
p = predict_dict(ex)
print("Probabilidade:", p, "->", f"{p*100:.1f}%")

# webhook_bot_api.py
from fastapi import FastAPI, Request
import requests, joblib, torch, numpy as np
from pyngrok import ngrok
import nest_asyncio, uvicorn

# --- config: cole seus tokens ---
BOT_TOKEN = "8023980472:AAGsr_115dRvxIddQ8lnQL_-28d1k6zt8u0"
NGROK_TOKEN = "32qY5dLWWTolN1ycUWtW31QV7LL_4AEYAYkqk3wpj8ZTLYM7G"
# ---------------------------------

# carregar scaler e modelo (usa CPU na inferência)
scaler = joblib.load("scaler.pkl")
model = HeartNN(len(FEATURES))
model.load_state_dict(torch.load("heart_model.pt", map_location=torch.device('cpu')))
model.eval()

# dados do estado de conversa (em memória)
CONV = {}  # chat_id -> {stage:int, data:dict}

QUESTIONS = [
    ("age", "Qual sua idade (em anos)?"),
    ("gender", "Sexo? Responda 'M' ou 'F'"),
    ("height", "Altura em cm? (ex: 170)"),
    ("weight", "Peso em kg? (ex: 75)"),
    ("ap_hi", "Pressão sistólica (valor numérico, ex: 120)"),
    ("ap_lo", "Pressão diastólica (ex: 80)"),
    ("cholesterol", "Colesterol (1=normal, 2=acima, 3=muito acima)"),
    ("gluc", "Glicemia (1=normal,2=acima,3=muito acima)"),
    ("smoke", "Você fuma? Responda 'sim' ou 'não'"),
    ("alco", "Consome álcool frequentemente? 'sim'/'não'"),
    ("active", "Pratica atividade física? 'sim'/'não'")
]

def send_message(chat_id, text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    requests.post(url, json={"chat_id": chat_id, "text": text})

def normalize_answer(key, text):
    text = text.strip().lower()
    if key == "gender":
        if text.startswith('m'):
            return 1  # considere 1 = male
        else:
            return 0  # female
    if key in ("smoke","alco","active"):
        return 1 if text.startswith('s') or text.startswith('y') else 0
    try:
        return float(text)
    except:
        return None

def compute_probability(data):
    # data must contain keys: age, gender, ap_hi, ap_lo, cholesterol, gluc, smoke, alco, active, height, weight or bmi
    if 'bmi' not in data:
        data['bmi'] = data['weight'] / ((data['height']/100)**2)
    arr = np.array([[ data[k] for k in FEATURES ]], dtype=float)
    arrs = scaler.transform(arr)
    xt = torch.tensor(arrs, dtype=torch.float32)
    with torch.no_grad():
        prob = model(xt).item()
    return prob

app = FastAPI()

@app.post("/webhook/{token}")
async def telegram_webhook(token: str, request: Request):
    if token != BOT_TOKEN:
        return {"ok": False, "error": "token mismatch"}
    upd = await request.json()
    # process message
    msg = upd.get("message")
    if not msg:
        return {"ok": True}
    chat_id = msg["chat"]["id"]
    text = msg.get("text", "").strip()
    # iniciar conversa
    if text.lower() == "/start":
        CONV[chat_id] = {"stage": 0, "data": {}}
        send_message(chat_id, "Olá! Vou calcular uma estimativa de risco. Preciso de alguns dados. (Sempre responda com números ou 'sim/nao').")
        send_message(chat_id, QUESTIONS[0][1])
        return {"ok": True}
    # se sem conversa, pedir para iniciar
    if chat_id not in CONV:
        send_message(chat_id, "Envie /start para começar.")
        return {"ok": True}
    # pegar estágio atual
    stage = CONV[chat_id]["stage"]
    key = QUESTIONS[stage][0]
    val = normalize_answer(key, text)
    if val is None:
        send_message(chat_id, "Entrada inválida. Por favor insira um valor numérico ou 'sim/nao'.")
        send_message(chat_id, QUESTIONS[stage][1])
        return {"ok": True}
    # salvar
    CONV[chat_id]["data"][key] = val
    CONV[chat_id]["stage"] += 1
    # next question or compute
    if CONV[chat_id]["stage"] < len(QUESTIONS):
        send_message(chat_id, QUESTIONS[ CONV[chat_id]['stage'] ][1])
    else:
        data = CONV[chat_id]["data"]
        # requer height & weight para BMI; se não foram, avisa (neste fluxo já pedimos)
        prob = compute_probability(data)
        pct = prob*100
        if prob < 0.10: risk = "Baixo"
        elif prob < 0.3: risk = "Médio"
        else: risk = "Alto"
        send_message(chat_id, f"Probabilidade estimada: {pct:.1f}%\nRisco: {risk}\n\nLembrete: isto é apenas uma estimativa. Procure atendimento médico para avaliação completa.")
        # limpar conversa
        del CONV[chat_id]
    return {"ok": True}

# --- Iniciar ngrok e setar webhook (execute quando pronto) ---
ngrok.set_auth_token(NGROK_TOKEN)
public_url = ngrok.connect(8000).public_url
print("URL pública (ngrok):", public_url)

# registrar webhook no Telegram (troque BOT_TOKEN se diferente)
resp = requests.get(f'https://api.telegram.org/bot{BOT_TOKEN}/setWebhook?url={public_url}/webhook/{BOT_TOKEN}')
print("setWebhook response:", resp.json())

# iniciar o servidor (bloqueante) - execute a célula e mantenha ela rodando
nest_asyncio.apply()
uvicorn.run(app, host="0.0.0.0", port=8000)